{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":26181,"status":"ok","timestamp":1714836659049,"user":{"displayName":"Vinitra","userId":"09606499732062179579"},"user_tz":240},"id":"tz4GjH2tQCVy","outputId":"713d7088-c792-4394-fa32-6c64c4d2ebe0"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["#mount drive\n","from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2262,"status":"ok","timestamp":1714836675813,"user":{"displayName":"Vinitra","userId":"09606499732062179579"},"user_tz":240},"id":"IJYf-GAtQzLp","outputId":"40558b18-e280-430a-e65d-9314911c2b15"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/UMass-Courses/Semester-2/CS670/UMass-CS670-Project\n","common\t\t\t  experiments\t\t   index.py\t\t  README.md\n","datautils\t\t  get_dataset.sh\t   last_run_info.json\t  SINet.ipynb\n","demo\t\t\t  github-repo-clone.ipynb  models\t\t  source-data\n","excluded-train-files.txt  Index.ipynb\t\t   preprocess_dataset.py  texture_params.txt\n"]}],"source":["# move into project directory\n","repo_name = \"UMass-CS670-Project\"\n","%cd /content/drive/MyDrive/UMass-Courses/Semester-2/CS670/$repo_name\n","!ls"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":53},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1713148079902,"user":{"displayName":"Vinitra Muralikrishnan","userId":"14239738625620892639"},"user_tz":240},"id":"rnSym0W0Rmz-","outputId":"69dfbd62-7d55-4ac5-d047-667bfaca25b0"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'\\n!pip3 install torch torchvision torchaudio\\n!pip install matplotlib numpy pandas pyyaml opencv-python\\n'"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["# set up environment\n","# comment out if not required\n","'''\n","!pip3 install torch torchvision torchaudio\n","!pip install matplotlib numpy pandas pyyaml opencv-python\n","'''"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VvSx-iP1P0Rx","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1714669620488,"user_tz":240,"elapsed":281782,"user":{"displayName":"VinitraMk","userId":"14045597532953840063"}},"outputId":"e1c24a4f-a04c-4196-880c-729c3566f519"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: gdown in /usr/local/lib/python3.10/dist-packages (5.1.0)\n","Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown) (4.12.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown) (3.13.4)\n","Requirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from gdown) (2.31.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gdown) (4.66.2)\n","Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown) (2.5)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2024.2.2)\n","Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (1.7.1)\n","Downloading...\n","From (original): https://drive.google.com/uc?id=1IAd2b7EtPqqXbFF3D9PLsHCDjMnr9UkL\n","From (redirected): https://drive.google.com/uc?id=1IAd2b7EtPqqXbFF3D9PLsHCDjMnr9UkL&confirm=t&uuid=f3b70e1d-fc4d-49b6-adcd-dbcabaabd792\n","To: /content/drive/MyDrive/UMass-Courses/Semester-2/CS670/UMass-CS670-Project/COD10K-v3.zip\n","100% 2.38G/2.38G [00:38<00:00, 61.3MB/s]\n"]}],"source":["# this cell is for downloading data.\n","# as of yet data is not hosted and is available in the private data folder\n","# uncomment the lines below  to download the data\n","\n","import os\n","\n","!pip install gdown\n","\n","data_dir=\"source-data\"\n","\n","if not(os.path.exists(\"source-data\")):\n","    !gdown https://drive.google.com/uc?id=1IAd2b7EtPqqXbFF3D9PLsHCDjMnr9UkL&export=download\n","    #echo 'Downloaded data! Unzipping to data folder'\n","    !unzip -qq -d . ./COD10K-v3.zip\n","    os.rename(\"./COD10K-v3.zip\", \"./source-data/COD10K-v3.zip\")\n","else:\n","    print(\"\\nThe data directory exists!\")"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"BboU3GhFP0R1","executionInfo":{"status":"ok","timestamp":1714836692595,"user_tz":240,"elapsed":12245,"user":{"displayName":"Vinitra","userId":"09606499732062179579"}}},"outputs":[],"source":["# setup some imports\n","from datautils.datareader import read_data\n","from datautils.dataset import COD10KDataset\n","from torch.utils.data import DataLoader\n","import random\n","import numpy as np\n","import torch\n","import argparse\n","from tqdm import tqdm\n","from torchvision.io import read_image\n","from torchvision.utils import save_image\n","from torchvision.transforms.functional import to_pil_image\n","import json\n","\n","from experiments.style_transfer import style_transfer\n","from common.visualizer import layer_visualizer"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"q7unXlk9haYV","executionInfo":{"status":"ok","timestamp":1714836692599,"user_tz":240,"elapsed":11,"user":{"displayName":"Vinitra","userId":"09606499732062179579"}}},"outputs":[],"source":["seed = 123\n","random.seed(seed)\n","np.random.seed(seed)\n","torch.manual_seed(seed)\n","torch.cuda.manual_seed(seed)\n","torch.backends.cudnn.deterministic = True"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"TwGytYYtenxa","executionInfo":{"status":"ok","timestamp":1714836700686,"user_tz":240,"elapsed":382,"user":{"displayName":"Vinitra","userId":"09606499732062179579"}}},"outputs":[],"source":["def run_style_transfer_pipeline(args, texture_name, style_weight, last_batch_run = -1):\n","    pos_data_paths = read_data('Train')\n","\n","    dataset = COD10KDataset(pos_data_paths)\n","    dataloader = DataLoader(dataset, batch_size = args.batch_size, shuffle = False)\n","\n","    for i_batch, batch in enumerate(dataloader):\n","        if i_batch > last_batch_run:\n","            print(f\"Processing batch {i_batch}, image: {batch['img_name']} of dimensions: {batch['img'].shape}\")\n","            style_img = read_image(f'./source-data/Textures/{texture_name}.jpg')\n","            new_img = style_transfer(\n","                batch['img'],\n","                style_img,\n","                [0, 2, 5, 14, 23],\n","                21,\n","                1e-4,\n","                [style_weight]*5,\n","                1e-5,\n","                args)\n","            img_name = batch['img_name'][0]\n","            img_name = img_name.replace(\".jpg\", \"\")\n","            img_name = f\"./source-data/Train/Styled-Image/{img_name}-Texture-{texture_name}.jpg\"\n","            save_image(new_img, img_name)\n","            last_run = {\n","                \"last_batch\": i_batch\n","            }\n","            print(f\"completing transfer of img {i_batch} with texture {texture_name}\")\n","            with open(\"./last_run_info.json\", \"w\") as fp:\n","                json.dump(last_run, fp)\n","\n","    print(f'Finished modifying train dataset images for {texture_name}')\n","    last_run = {\n","        \"last_batch\": -1\n","    }\n","    with open(\"./last_run_info.json\", \"w\") as fp:\n","        json.dump(last_run, fp)\n","    '''\n","    style_img = read_image(f'./data/Textures/{texture_name}.jpg')\n","    content_img = read_image('./data/Mini-Set/butterfly-image.jpg')\n","    #content_img = batch['img']\n","    print('b4 trans', content_img.shape)\n","    new_img = style_transfer(content_img,\n","            style_img,\n","            [0, 2, 5, 14, 23],\n","            21,\n","            1e-4,\n","            [style_weight]*5,\n","            1e-5,\n","            args)\n","    #pi = to_pil_image(pi)\n","    #plt.axis(\"off\")\n","    #plt.imshow(pi)\n","    #plt.show()\n","    save_image(new_img, f'./data/COD10K-v3/Train/Styled-Image/butterfly-image-Texture-{texture_name}.jpg')\n","    #print('after trans', new_img.size())\n","    '''\n","    return -1"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"PoM2h30rU6FQ","outputId":"d3df9406-6699-40c3-88d0-65201b9fa5aa","executionInfo":{"status":"error","timestamp":1714840145978,"user_tz":240,"elapsed":3434767,"user":{"displayName":"Vinitra","userId":"09606499732062179579"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Processing batch 1708, image: ['COD10K-CAM-2-Terrestrial-37-Lion-2114.jpg'] of dimensions: torch.Size([1, 3, 683, 1024])\n"]},{"output_type":"stream","name":"stderr","text":["Downloading: \"https://download.pytorch.org/models/vgg19-dcbb9e9d.pth\" to /root/.cache/torch/hub/checkpoints/vgg19-dcbb9e9d.pth\n","100%|██████████| 548M/548M [00:06<00:00, 93.7MB/s]\n"]},{"output_type":"stream","name":"stdout","text":["completing transfer of img 1708 with texture moss\n","Processing batch 1709, image: ['COD10K-CAM-2-Terrestrial-46-StickInsect-2862.jpg'] of dimensions: torch.Size([1, 3, 683, 1024])\n","completing transfer of img 1709 with texture moss\n","Processing batch 1710, image: ['COD10K-CAM-4-Amphibian-68-Toad-4984.jpg'] of dimensions: torch.Size([1, 3, 651, 1023])\n","completing transfer of img 1710 with texture moss\n","Processing batch 1711, image: ['COD10K-CAM-2-Terrestrial-48-Wolf-2915.jpg'] of dimensions: torch.Size([1, 3, 573, 1024])\n","completing transfer of img 1711 with texture moss\n","Processing batch 1712, image: ['COD10K-CAM-2-Terrestrial-38-Lizard-2280.jpg'] of dimensions: torch.Size([1, 3, 683, 1024])\n","completing transfer of img 1712 with texture moss\n","Processing batch 1713, image: ['COD10K-CAM-4-Amphibian-67-Frog-4716.jpg'] of dimensions: torch.Size([1, 3, 1024, 679])\n","completing transfer of img 1713 with texture moss\n","Processing batch 1714, image: ['COD10K-CAM-2-Terrestrial-38-Lizard-2317.jpg'] of dimensions: torch.Size([1, 3, 683, 1024])\n","completing transfer of img 1714 with texture moss\n","Processing batch 1715, image: ['COD10K-CAM-3-Flying-59-Grasshopper-3754.jpg'] of dimensions: torch.Size([1, 3, 665, 1024])\n","completing transfer of img 1715 with texture moss\n","Processing batch 1716, image: ['COD10K-CAM-2-Terrestrial-45-Spider-2530.jpg'] of dimensions: torch.Size([1, 3, 683, 1024])\n","completing transfer of img 1716 with texture moss\n","Processing batch 1717, image: ['COD10K-CAM-3-Flying-59-Grasshopper-3616.jpg'] of dimensions: torch.Size([1, 3, 683, 1024])\n","completing transfer of img 1717 with texture moss\n","Processing batch 1718, image: ['COD10K-CAM-1-Aquatic-13-Pipefish-562.jpg'] of dimensions: torch.Size([1, 3, 638, 1022])\n","completing transfer of img 1718 with texture moss\n","Processing batch 1719, image: ['COD10K-CAM-3-Flying-59-Grasshopper-3829.jpg'] of dimensions: torch.Size([1, 3, 733, 1280])\n","completing transfer of img 1719 with texture moss\n","Processing batch 1720, image: ['COD10K-CAM-1-Aquatic-6-Fish-206.jpg'] of dimensions: torch.Size([1, 3, 683, 1024])\n","completing transfer of img 1720 with texture moss\n","Processing batch 1721, image: ['COD10K-CAM-2-Terrestrial-26-Chameleon-1683.jpg'] of dimensions: torch.Size([1, 3, 640, 480])\n","completing transfer of img 1721 with texture moss\n","Processing batch 1722, image: ['COD10K-CAM-3-Flying-65-Owl-4576.jpg'] of dimensions: torch.Size([1, 3, 768, 1024])\n","completing transfer of img 1722 with texture moss\n","Processing batch 1723, image: ['COD10K-CAM-2-Terrestrial-23-Cat-1517.jpg'] of dimensions: torch.Size([1, 3, 1024, 768])\n","completing transfer of img 1723 with texture moss\n","Processing batch 1724, image: ['COD10K-CAM-3-Flying-65-Owl-4512.jpg'] of dimensions: torch.Size([1, 3, 908, 880])\n","completing transfer of img 1724 with texture moss\n","Processing batch 1725, image: ['COD10K-CAM-3-Flying-56-Cicada-3477.jpg'] of dimensions: torch.Size([1, 3, 686, 1024])\n","completing transfer of img 1725 with texture moss\n","Processing batch 1726, image: ['COD10K-CAM-3-Flying-62-Mantis-4291.jpg'] of dimensions: torch.Size([1, 3, 706, 1000])\n","completing transfer of img 1726 with texture moss\n","Processing batch 1727, image: ['COD10K-CAM-3-Flying-64-Moth-4435.jpg'] of dimensions: torch.Size([1, 3, 683, 1024])\n","completing transfer of img 1727 with texture moss\n","Processing batch 1728, image: ['COD10K-CAM-2-Terrestrial-42-Sciuridae-2396.jpg'] of dimensions: torch.Size([1, 3, 951, 1024])\n","completing transfer of img 1728 with texture moss\n","Processing batch 1729, image: ['COD10K-CAM-2-Terrestrial-45-Spider-2657.jpg'] of dimensions: torch.Size([1, 3, 1024, 1023])\n","completing transfer of img 1729 with texture moss\n","Processing batch 1730, image: ['COD10K-CAM-3-Flying-53-Bird-3194.jpg'] of dimensions: torch.Size([1, 3, 769, 1024])\n","completing transfer of img 1730 with texture moss\n","Processing batch 1731, image: ['COD10K-CAM-1-Aquatic-13-Pipefish-659.jpg'] of dimensions: torch.Size([1, 3, 652, 1024])\n","completing transfer of img 1731 with texture moss\n","Processing batch 1732, image: ['COD10K-CAM-2-Terrestrial-45-Spider-2639.jpg'] of dimensions: torch.Size([1, 3, 722, 1023])\n","completing transfer of img 1732 with texture moss\n","Processing batch 1733, image: ['COD10K-CAM-2-Terrestrial-24-Caterpillar-1620.jpg'] of dimensions: torch.Size([1, 3, 576, 1024])\n","completing transfer of img 1733 with texture moss\n","Processing batch 1734, image: ['COD10K-CAM-4-Amphibian-68-Toad-4843.jpg'] of dimensions: torch.Size([1, 3, 600, 800])\n","completing transfer of img 1734 with texture moss\n","Processing batch 1735, image: ['COD10K-CAM-2-Terrestrial-38-Lizard-2292.jpg'] of dimensions: torch.Size([1, 3, 683, 1024])\n","completing transfer of img 1735 with texture moss\n","Processing batch 1736, image: ['COD10K-CAM-3-Flying-59-Grasshopper-3774.jpg'] of dimensions: torch.Size([1, 3, 768, 1024])\n","completing transfer of img 1736 with texture moss\n","Processing batch 1737, image: ['COD10K-CAM-1-Aquatic-3-Crab-90.jpg'] of dimensions: torch.Size([1, 3, 768, 1024])\n","completing transfer of img 1737 with texture moss\n","Processing batch 1738, image: ['COD10K-CAM-3-Flying-53-Bird-3182.jpg'] of dimensions: torch.Size([1, 3, 853, 1280])\n","completing transfer of img 1738 with texture moss\n","Processing batch 1739, image: ['COD10K-CAM-1-Aquatic-13-Pipefish-645.jpg'] of dimensions: torch.Size([1, 3, 684, 1024])\n","completing transfer of img 1739 with texture moss\n","Processing batch 1740, image: ['COD10K-CAM-1-Aquatic-13-Pipefish-761.jpg'] of dimensions: torch.Size([1, 3, 713, 1024])\n","completing transfer of img 1740 with texture moss\n","Processing batch 1741, image: ['COD10K-CAM-1-Aquatic-15-SeaHorse-1051.jpg'] of dimensions: torch.Size([1, 3, 978, 746])\n","completing transfer of img 1741 with texture moss\n","Processing batch 1742, image: ['COD10K-CAM-2-Terrestrial-38-Lizard-2226.jpg'] of dimensions: torch.Size([1, 3, 683, 1024])\n","completing transfer of img 1742 with texture moss\n","Processing batch 1743, image: ['COD10K-CAM-1-Aquatic-13-Pipefish-824.jpg'] of dimensions: torch.Size([1, 3, 750, 1000])\n","completing transfer of img 1743 with texture moss\n","Processing batch 1744, image: ['COD10K-CAM-4-Amphibian-67-Frog-4680.jpg'] of dimensions: torch.Size([1, 3, 660, 880])\n","completing transfer of img 1744 with texture moss\n","Processing batch 1745, image: ['COD10K-CAM-2-Terrestrial-21-Ant-1235.jpg'] of dimensions: torch.Size([1, 3, 683, 1024])\n","completing transfer of img 1745 with texture moss\n","Processing batch 1746, image: ['COD10K-CAM-3-Flying-62-Mantis-4381.jpg'] of dimensions: torch.Size([1, 3, 678, 1024])\n","completing transfer of img 1746 with texture moss\n","Processing batch 1747, image: ['COD10K-CAM-3-Flying-53-Bird-3193.jpg'] of dimensions: torch.Size([1, 3, 683, 1024])\n","completing transfer of img 1747 with texture moss\n","Processing batch 1748, image: ['COD10K-CAM-2-Terrestrial-31-Gecko-1894.jpg'] of dimensions: torch.Size([1, 3, 683, 1024])\n","completing transfer of img 1748 with texture moss\n","Processing batch 1749, image: ['COD10K-CAM-4-Amphibian-68-Toad-4817.jpg'] of dimensions: torch.Size([1, 3, 853, 1280])\n","completing transfer of img 1749 with texture moss\n","Processing batch 1750, image: ['COD10K-CAM-1-Aquatic-13-Pipefish-755.jpg'] of dimensions: torch.Size([1, 3, 768, 1024])\n","completing transfer of img 1750 with texture moss\n","Processing batch 1751, image: ['COD10K-CAM-2-Terrestrial-23-Cat-1521.jpg'] of dimensions: torch.Size([1, 3, 540, 720])\n","completing transfer of img 1751 with texture moss\n","Processing batch 1752, image: ['COD10K-CAM-3-Flying-64-Moth-4468.jpg'] of dimensions: torch.Size([1, 3, 670, 1024])\n","completing transfer of img 1752 with texture moss\n","Processing batch 1753, image: ['COD10K-CAM-1-Aquatic-13-Pipefish-708.jpg'] of dimensions: torch.Size([1, 3, 1024, 683])\n","completing transfer of img 1753 with texture moss\n","Processing batch 1754, image: ['COD10K-CAM-1-Aquatic-6-Fish-144.jpg'] of dimensions: torch.Size([1, 3, 768, 1024])\n","completing transfer of img 1754 with texture moss\n","Processing batch 1755, image: ['COD10K-CAM-1-Aquatic-13-Pipefish-786.jpg'] of dimensions: torch.Size([1, 3, 768, 1024])\n","completing transfer of img 1755 with texture moss\n","Processing batch 1756, image: ['COD10K-CAM-2-Terrestrial-35-Kangaroo-2051.jpg'] of dimensions: torch.Size([1, 3, 683, 1024])\n","completing transfer of img 1756 with texture moss\n","Processing batch 1757, image: ['COD10K-CAM-2-Terrestrial-45-Spider-2681.jpg'] of dimensions: torch.Size([1, 3, 731, 1024])\n","completing transfer of img 1757 with texture moss\n","Processing batch 1758, image: ['COD10K-CAM-3-Flying-65-Owl-4546.jpg'] of dimensions: torch.Size([1, 3, 737, 1024])\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-6-dbc4c28bf497>\u001b[0m in \u001b[0;36m<cell line: 45>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;31m#layer_visualizer(img, args)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m     \u001b[0mrun_style_transfer_pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtexture\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtexture\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'style_weights'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_run\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-5-27874db84f89>\u001b[0m in \u001b[0;36mrun_style_transfer_pipeline\u001b[0;34m(args, texture_name, style_weight, last_batch_run)\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Processing batch {i_batch}, image: {batch['img_name']} of dimensions: {batch['img'].shape}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0mstyle_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'./source-data/Textures/{texture_name}.jpg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m             new_img = style_transfer(\n\u001b[0m\u001b[1;32m     12\u001b[0m                 \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'img'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0mstyle_img\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/drive/MyDrive/UMass-Courses/Semester-2/CS670/UMass-CS670-Project/experiments/style_transfer.py\u001b[0m in \u001b[0;36mstyle_transfer\u001b[0;34m(content_img, style_img, style_layers, content_layer, content_weight, style_weights, tv_weight, args)\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m__get_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0mcloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m__content_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcontent_layer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontent_trgt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m         \u001b[0msloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m__style_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstyle_layers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstyle_grams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstyle_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m         \u001b[0mtloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m__tv_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtv_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcloss\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m*\u001b[0m \u001b[0msloss\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/drive/MyDrive/UMass-Courses/Semester-2/CS670/UMass-CS670-Project/experiments/style_transfer.py\u001b[0m in \u001b[0;36m__style_loss\u001b[0;34m(features, style_layers, style_grams, style_weights)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mstloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuda'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mstloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["\n","param_dict = {\n","    'moss': {\n","        'epochs': 100,\n","        'style_weights': 0.5\n","    },\n","    'snow': {\n","        'epochs': 200,\n","        'style_weights': 1.5\n","    },\n","    'wet-sand': {\n","        'epochs': 200,\n","        'style_weights': 3.5\n","    },\n","    'sand-with-moss': {\n","        'epochs': 100,\n","        'style_weights': 2.5\n","    },\n","    'rain': {\n","        'epochs': 100,\n","        'style_weights': 4.5\n","    },\n","    'wood': {\n","        'epochs': 100,\n","        'style_weights': 0.5\n","    },\n","    'grass': {\n","        'epochs': 100,\n","        'style_weights': 0.1\n","    },\n","    'foliage-texture': {\n","        'epochs': 100,\n","        'style_weights': 0.5\n","    },\n","    'blue-coral': {\n","        'epochs': 100,\n","        'style_weights': 1.1\n","    }\n","}\n","\n","with open(\"./last_run_info.json\") as fp:\n","    last_run = json.load(fp)[\"last_batch\"]\n","\n","selected_textures = ['moss', 'wet-sand', 'sand-with-moss', 'rain', 'foliage-texture']\n","\n","for texture in selected_textures:\n","\n","    parser = argparse.ArgumentParser()\n","    parser.add_argument('--batch_size', type = int, default = 1)\n","    parser.add_argument('--model_name', type=str, default='vgg')\n","    parser.add_argument('--lr', type=float, default=0.05)\n","    parser.add_argument('--max_iter', type=int, default=param_dict[texture]['epochs'])\n","    args = parser.parse_args(args=[])\n","\n","    #style_img = read_image(f'./data/Textures/{texture}.jpg')\n","    #print(img.size())\n","    #layer_visualizer(img, args)\n","\n","    run_style_transfer_pipeline(args, texture, param_dict[texture]['style_weights'], last_run)"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13"}},"nbformat":4,"nbformat_minor":0}