{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":33022,"status":"ok","timestamp":1714573005937,"user":{"displayName":"Vinitra","userId":"09606499732062179579"},"user_tz":240},"id":"tz4GjH2tQCVy","outputId":"6d0f0a3c-e1ba-48be-a13f-9c0022b4307e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["#mount drive\n","from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":421,"status":"ok","timestamp":1714571203822,"user":{"displayName":"Vinitra","userId":"09606499732062179579"},"user_tz":240},"id":"IJYf-GAtQzLp","outputId":"6ddb3c83-9c39-411c-f05c-3906018e23ea"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/UMass-Courses/Semester-2/CS670/UMass-CS670-Project\n","common\t   experiments\t\t    Index.ipynb\t\tmodels\t\t       SINet.ipynb\n","datautils  get_dataset.sh\t    index.py\t\tpreprocess_dataset.py  source-data\n","demo\t   github-repo-clone.ipynb  last_run_info.json\tREADME.md\t       texture_params.txt\n"]}],"source":["# move into project directory\n","repo_name = \"UMass-CS670-Project\"\n","%cd /content/drive/MyDrive/UMass-Courses/Semester-2/CS670/$repo_name\n","!ls"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":53},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1713148079902,"user":{"displayName":"Vinitra Muralikrishnan","userId":"14239738625620892639"},"user_tz":240},"id":"rnSym0W0Rmz-","outputId":"69dfbd62-7d55-4ac5-d047-667bfaca25b0"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'\\n!pip3 install torch torchvision torchaudio\\n!pip install matplotlib numpy pandas pyyaml opencv-python\\n'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":3}],"source":["# set up environment\n","# comment out if not required\n","'''\n","!pip3 install torch torchvision torchaudio\n","!pip install matplotlib numpy pandas pyyaml opencv-python\n","'''"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":266210,"status":"ok","timestamp":1714536010989,"user":{"displayName":"Vinitra","userId":"09606499732062179579"},"user_tz":240},"id":"VvSx-iP1P0Rx","colab":{"base_uri":"https://localhost:8080/"},"outputId":"6480b970-ea0b-472e-ba31-930e3478b331"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: gdown in /usr/local/lib/python3.10/dist-packages (5.1.0)\n","Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown) (4.12.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown) (3.13.4)\n","Requirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from gdown) (2.31.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gdown) (4.66.2)\n","Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown) (2.5)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2024.2.2)\n","Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (1.7.1)\n","Downloading...\n","From (original): https://drive.google.com/uc?id=18oBjWeuw5qAq4HG_jZdjUHas4APy-KJE\n","From (redirected): https://drive.google.com/uc?id=18oBjWeuw5qAq4HG_jZdjUHas4APy-KJE&confirm=t&uuid=08ee156c-0356-48f7-84f5-ca61d0cc5469\n","To: /content/drive/MyDrive/UMass-Courses/Semester-2/CS670/UMass-CS670-Project/COD10K-v3.zip\n","100% 2.38G/2.38G [00:38<00:00, 62.4MB/s]\n"]}],"source":["# this cell is for downloading data.\n","# as of yet data is not hosted and is available in the private data folder\n","# uncomment the lines below  to download the data\n","\n","import os\n","\n","!pip install gdown\n","\n","data_dir=\"source-data\"\n","\n","if not(os.path.exists(\"source-data\")):\n","    !gdown https://drive.google.com/uc?id=18oBjWeuw5qAq4HG_jZdjUHas4APy-KJE&export=download\n","    #echo 'Downloaded data! Unzipping to data folder'\n","    !unzip -qq -d . ./COD10K-v3.zip\n","    os.rename(\"./COD10K-v3.zip\", \"./source-data/COD10K-v3.zip\")\n","else:\n","    print(\"\\nThe data directory exists!\")"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":6465,"status":"ok","timestamp":1714571210285,"user":{"displayName":"Vinitra","userId":"09606499732062179579"},"user_tz":240},"id":"BboU3GhFP0R1"},"outputs":[],"source":["# setup some imports\n","from datautils.datareader import read_data\n","from datautils.dataset import COD10KDataset\n","from torch.utils.data import DataLoader\n","import random\n","import numpy as np\n","import torch\n","import argparse\n","from tqdm import tqdm\n","from torchvision.io import read_image\n","from torchvision.utils import save_image\n","from torchvision.transforms.functional import to_pil_image\n","import json\n","\n","from experiments.style_transfer import style_transfer\n","from common.visualizer import layer_visualizer"]},{"cell_type":"code","source":["seed = 123\n","random.seed(seed)\n","np.random.seed(seed)\n","torch.manual_seed(seed)\n","torch.cuda.manual_seed(seed)\n","torch.backends.cudnn.deterministic = True"],"metadata":{"id":"q7unXlk9haYV","executionInfo":{"status":"ok","timestamp":1714571210286,"user_tz":240,"elapsed":32,"user":{"displayName":"Vinitra","userId":"09606499732062179579"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["def run_style_transfer_pipeline(args, texture_name, style_weight, last_batch_run = -1):\n","    pos_data_paths = read_data('Train')\n","\n","    dataset = COD10KDataset(pos_data_paths)\n","    dataloader = DataLoader(dataset, batch_size = args.batch_size, shuffle = False)\n","\n","    for i_batch, batch in enumerate(dataloader):\n","        if i_batch > last_batch_run:\n","            print(f\"Processing batch {i_batch}, image: {batch['img_name']} of dimensions: {batch['img'].shape}\")\n","            style_img = read_image(f'./source-data/Textures/{texture_name}.jpg')\n","            new_img = style_transfer(\n","                batch['img'],\n","                style_img,\n","                [0, 2, 5, 14, 23],\n","                21,\n","                1e-4,\n","                [style_weight]*5,\n","                1e-5,\n","                args)\n","            img_name = batch['img_name'][0]\n","            img_name = img_name.replace(\".jpg\", \"\")\n","            img_name = f\"./source-data/Train/Styled-Image/{img_name}-Texture-{texture_name}.jpg\"\n","            save_image(new_img, img_name)\n","            last_run = {\n","                \"last_batch\": i_batch\n","            }\n","            print(f\"completing transfer of img {i_batch} with texture {texture_name}\")\n","            with open(\"./last_run_info.json\", \"w\") as fp:\n","                json.dump(last_run, fp)\n","\n","    '''\n","    style_img = read_image(f'./data/Textures/{texture_name}.jpg')\n","    content_img = read_image('./data/Mini-Set/butterfly-image.jpg')\n","    #content_img = batch['img']\n","    print('b4 trans', content_img.shape)\n","    new_img = style_transfer(content_img,\n","            style_img,\n","            [0, 2, 5, 14, 23],\n","            21,\n","            1e-4,\n","            [style_weight]*5,\n","            1e-5,\n","            args)\n","    #pi = to_pil_image(pi)\n","    #plt.axis(\"off\")\n","    #plt.imshow(pi)\n","    #plt.show()\n","    save_image(new_img, f'./data/COD10K-v3/Train/Styled-Image/butterfly-image-Texture-{texture_name}.jpg')\n","    #print('after trans', new_img.size())\n","    '''"],"metadata":{"id":"TwGytYYtenxa","executionInfo":{"status":"ok","timestamp":1714571210287,"user_tz":240,"elapsed":31,"user":{"displayName":"Vinitra","userId":"09606499732062179579"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["\n","param_dict = {\n","    'moss': {\n","        'epochs': 100,\n","        'style_weights': 0.5\n","    },\n","    'snow': {\n","        'epochs': 200,\n","        'style_weights': 1.5\n","    },\n","    'wet-sand': {\n","        'epochs': 200,\n","        'style_weights': 3.5\n","    },\n","    'sand-with-moss': {\n","        'epochs': 100,\n","        'style_weights': 2.5\n","    },\n","    'rain': {\n","        'epochs': 100,\n","        'style_weights': 4.5\n","    },\n","    'wood': {\n","        'epochs': 100,\n","        'style_weights': 0.5\n","    },\n","    'grass': {\n","        'epochs': 100,\n","        'style_weights': 0.1\n","    },\n","    'foliage-texture': {\n","        'epochs': 100,\n","        'style_weights': 0.5\n","    },\n","    'blue-coral': {\n","        'epochs': 100,\n","        'style_weights': 1.1\n","    }\n","}\n","\n","with open(\"./last_run_info.json\") as fp:\n","    last_run = json.load(fp)[\"last_batch\"]\n","\n","selected_textures = ['moss', 'wet-sand', 'sand-with-moss', 'rain', 'foliage-texture']\n","\n","for texture in selected_textures:\n","    parser = argparse.ArgumentParser()\n","    parser.add_argument('--batch_size', type = int, default = 1)\n","    parser.add_argument('--model_name', type=str, default='vgg')\n","    parser.add_argument('--lr', type=float, default=0.05)\n","    parser.add_argument('--max_iter', type=int, default=param_dict[texture]['epochs'])\n","    args = parser.parse_args(args=[])\n","\n","    #style_img = read_image(f'./data/Textures/{texture}.jpg')\n","    #print(img.size())\n","    #layer_visualizer(img, args)\n","\n","    run_style_transfer_pipeline(args, texture, param_dict[texture]['style_weights'], last_run)"],"metadata":{"id":"PoM2h30rU6FQ","colab":{"base_uri":"https://localhost:8080/"},"outputId":"4a98a84d-82d5-4543-813d-2cb314d9fd7c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Processing batch 573, image: ['COD10K-CAM-1-Aquatic-6-Fish-142.jpg'] of dimensions: torch.Size([1, 3, 685, 1023])\n","completing transfer of img 573 with texture moss\n","Processing batch 574, image: ['COD10K-CAM-2-Terrestrial-34-Human-2001.jpg'] of dimensions: torch.Size([1, 3, 683, 1024])\n","completing transfer of img 574 with texture moss\n","Processing batch 575, image: ['COD10K-CAM-2-Terrestrial-45-Spider-2619.jpg'] of dimensions: torch.Size([1, 3, 683, 1024])\n","completing transfer of img 575 with texture moss\n","Processing batch 576, image: ['COD10K-CAM-2-Terrestrial-23-Cat-1319.jpg'] of dimensions: torch.Size([1, 3, 768, 1023])\n","completing transfer of img 576 with texture moss\n","Processing batch 577, image: ['COD10K-CAM-3-Flying-62-Mantis-4284.jpg'] of dimensions: torch.Size([1, 3, 934, 683])\n","completing transfer of img 577 with texture moss\n","Processing batch 578, image: ['COD10K-CAM-1-Aquatic-15-SeaHorse-1059.jpg'] of dimensions: torch.Size([1, 3, 1009, 619])\n","completing transfer of img 578 with texture moss\n","Processing batch 579, image: ['COD10K-CAM-3-Flying-62-Mantis-4282.jpg'] of dimensions: torch.Size([1, 3, 768, 1024])\n","completing transfer of img 579 with texture moss\n","Processing batch 580, image: ['COD10K-CAM-3-Flying-62-Mantis-4377.jpg'] of dimensions: torch.Size([1, 3, 768, 1024])\n","completing transfer of img 580 with texture moss\n","Processing batch 581, image: ['COD10K-CAM-3-Flying-55-Butterfly-3365.jpg'] of dimensions: torch.Size([1, 3, 683, 1024])\n","completing transfer of img 581 with texture moss\n","Processing batch 582, image: ['COD10K-CAM-1-Aquatic-13-Pipefish-516.jpg'] of dimensions: torch.Size([1, 3, 1023, 593])\n","completing transfer of img 582 with texture moss\n","Processing batch 583, image: ['COD10K-CAM-1-Aquatic-19-Stingaree-1200.jpg'] of dimensions: torch.Size([1, 3, 410, 1022])\n","completing transfer of img 583 with texture moss\n","Processing batch 584, image: ['COD10K-CAM-2-Terrestrial-38-Lizard-2170.jpg'] of dimensions: torch.Size([1, 3, 853, 1280])\n","completing transfer of img 584 with texture moss\n","Processing batch 585, image: ['COD10K-CAM-2-Terrestrial-38-Lizard-2311.jpg'] of dimensions: torch.Size([1, 3, 626, 1024])\n","completing transfer of img 585 with texture moss\n","Processing batch 586, image: ['COD10K-CAM-3-Flying-51-Bee-2984.jpg'] of dimensions: torch.Size([1, 3, 507, 754])\n","completing transfer of img 586 with texture moss\n","Processing batch 587, image: ['COD10K-CAM-4-Amphibian-67-Frog-4730.jpg'] of dimensions: torch.Size([1, 3, 853, 1280])\n","completing transfer of img 587 with texture moss\n","Processing batch 588, image: ['COD10K-CAM-3-Flying-54-Bittern-3267.jpg'] of dimensions: torch.Size([1, 3, 1023, 939])\n","completing transfer of img 588 with texture moss\n","Processing batch 589, image: ['COD10K-CAM-2-Terrestrial-38-Lizard-2255.jpg'] of dimensions: torch.Size([1, 3, 768, 1024])\n","completing transfer of img 589 with texture moss\n","Processing batch 590, image: ['COD10K-CAM-1-Aquatic-13-Pipefish-839.jpg'] of dimensions: torch.Size([1, 3, 768, 1024])\n","completing transfer of img 590 with texture moss\n","Processing batch 591, image: ['COD10K-CAM-2-Terrestrial-27-Cheetah-1740.jpg'] of dimensions: torch.Size([1, 3, 1050, 1599])\n","completing transfer of img 591 with texture moss\n","Processing batch 592, image: ['COD10K-CAM-1-Aquatic-19-Stingaree-1195.jpg'] of dimensions: torch.Size([1, 3, 768, 1024])\n"]}]}],"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}