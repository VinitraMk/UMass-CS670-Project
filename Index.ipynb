{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":5930,"status":"ok","timestamp":1715087477768,"user":{"displayName":"Vinitra Muralikrishnan","userId":"14239738625620892639"},"user_tz":240},"id":"tz4GjH2tQCVy","colab":{"base_uri":"https://localhost:8080/"},"outputId":"4a28cb5f-926f-4600-cabe-b8a8013aa4db"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["#mount drive\n","from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1715087477768,"user":{"displayName":"Vinitra Muralikrishnan","userId":"14239738625620892639"},"user_tz":240},"id":"IJYf-GAtQzLp","outputId":"f34eaf58-01d5-4dca-ad1a-8d0eb3cf51c0"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/UMass-Courses/Semester-2/CS670/UMass-CS670-Project\n","common\t\t\t  experiments\t\t   last_run_info.json\t  source-data\n","config.yaml\t\t  get_dataset.sh\t   models\t\t  texture_params.txt\n","datautils\t\t  github-repo-clone.ipynb  preprocess_dataset.py\n","demo\t\t\t  Index.ipynb\t\t   README.md\n","excluded-train-files.txt  index.py\t\t   SINet.ipynb\n"]}],"source":["# move into project directory\n","repo_name = \"UMass-CS670-Project\"\n","%cd /content/drive/MyDrive/UMass-Courses/Semester-2/CS670/$repo_name\n","!ls"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":53},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1713148079902,"user":{"displayName":"Vinitra Muralikrishnan","userId":"14239738625620892639"},"user_tz":240},"id":"rnSym0W0Rmz-","outputId":"69dfbd62-7d55-4ac5-d047-667bfaca25b0"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'\\n!pip3 install torch torchvision torchaudio\\n!pip install matplotlib numpy pandas pyyaml opencv-python\\n'"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["# set up environment\n","# comment out if not required\n","'''\n","!pip3 install torch torchvision torchaudio\n","!pip install matplotlib numpy pandas pyyaml opencv-python\n","'''"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VvSx-iP1P0Rx","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1714973020069,"user_tz":240,"elapsed":5539,"user":{"displayName":"Vinitra Muralikrishnan","userId":"14239738625620892639"}},"outputId":"2154d097-f0e2-4f2a-eef6-53a5fb2858c1"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: gdown in /usr/local/lib/python3.10/dist-packages (5.1.0)\n","Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown) (4.12.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown) (3.14.0)\n","Requirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from gdown) (2.31.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gdown) (4.66.2)\n","Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown) (2.5)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2024.2.2)\n","Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (1.7.1)\n","\n","The data directory exists!\n"]}],"source":["# this cell is for downloading data.\n","# as of yet data is not hosted and is available in the private data folder\n","# uncomment the lines below  to download the data\n","\n","import os\n","\n","!pip install gdown\n","\n","data_dir=\"source-data\"\n","\n","if not(os.path.exists(\"source-data\")):\n","    #!gdown https://drive.google.com/uc?id=18oBjWeuw5qAq4HG_jZdjUHas4APy-KJE&export=download\n","    #echo 'Downloaded data! Unzipping to data folder'\n","    !unzip -qq -d . ./COD10K-v3.zip\n","    os.rename(\"./COD10K-v3.zip\", \"./source-data/COD10K-v3.zip\")\n","else:\n","    print(\"\\nThe data directory exists!\")"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"BboU3GhFP0R1","executionInfo":{"status":"ok","timestamp":1715087481666,"user_tz":240,"elapsed":3902,"user":{"displayName":"Vinitra Muralikrishnan","userId":"14239738625620892639"}}},"outputs":[],"source":["# setup some imports\n","from datautils.datareader import read_data\n","from datautils.dataset import COD10KDataset\n","from torch.utils.data import DataLoader\n","import random\n","import numpy as np\n","import torch\n","import argparse\n","from tqdm import tqdm\n","from torchvision.io import read_image\n","from torchvision.utils import save_image\n","from torchvision.transforms.functional import to_pil_image\n","import json\n","\n","from experiments.style_transfer import style_transfer\n","from common.visualizer import layer_visualizer\n","from common.utils import init_config"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"q7unXlk9haYV","executionInfo":{"status":"ok","timestamp":1715087481667,"user_tz":240,"elapsed":7,"user":{"displayName":"Vinitra Muralikrishnan","userId":"14239738625620892639"}}},"outputs":[],"source":["seed = 123\n","random.seed(seed)\n","np.random.seed(seed)\n","torch.manual_seed(seed)\n","torch.cuda.manual_seed(seed)\n","torch.backends.cudnn.deterministic = True"]},{"cell_type":"code","source":["config_params = init_config()\n","print(config_params)"],"metadata":{"id":"oPg2Qi7OUBPz","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1715087484530,"user_tz":240,"elapsed":8,"user":{"displayName":"Vinitra Muralikrishnan","userId":"14239738625620892639"}},"outputId":"87de2ef0-d37c-470d-f7f4-a4d3b20e7141"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["{'data_dir': '/content/drive/MyDrive/UMass-Courses/Semester-2/CS670/UMass-CS670-Project/source-data', 'device': 'cuda', 'root_dir': '/content/drive/MyDrive/UMass-Courses/Semester-2/CS670/UMass-CS670-Project', 'use_gpu': True}\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TwGytYYtenxa"},"outputs":[],"source":["def run_style_transfer_pipeline(args, texture_name, style_weight, last_batch_run = -1):\n","    pos_data_paths = read_data('Train')\n","\n","    dataset = COD10KDataset(pos_data_paths)\n","\n","    dataloader = DataLoader(dataset, batch_size = args.batch_size, shuffle = False)\n","\n","    for i_batch, batch in enumerate(dataloader):\n","        if i_batch > last_batch_run:\n","            print(f\"Processing batch {i_batch}, image: {batch['img_name']} of dimensions: {batch['img'].shape}\")\n","            style_img = read_image(f'./source-data/Textures/{texture_name}.jpg')\n","            new_img = style_transfer(\n","                batch['img'],\n","                style_img,\n","                [0, 2, 5, 14, 23],\n","                21,\n","                1e-4,\n","                [style_weight]*5,\n","                1e-5,\n","                args)\n","            img_name = batch['img_name'][0]\n","            img_name = img_name.replace(\".jpg\", \"\")\n","            img_name = f\"./source-data/Train/Styled-Image/{img_name}-Texture-{texture_name}.jpg\"\n","            save_image(new_img, img_name)\n","            last_run = {\n","                \"last_batch\": i_batch\n","            }\n","            print(f\"completing transfer of img {i_batch} with texture {texture_name}\")\n","            with open(\"./last_run_info.json\", \"w\") as fp:\n","                json.dump(last_run, fp)\n","\n","    print(f'Finished modifying train dataset images for {texture_name}')\n","    last_run = {\n","        \"last_batch\": -1\n","    }\n","    with open(\"./last_run_info.json\", \"w\") as fp:\n","        json.dump(last_run, fp)\n","    return -1"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PoM2h30rU6FQ"},"outputs":[],"source":["\n","param_dict = {\n","    'moss': {\n","        'epochs': 100,\n","        'style_weights': 0.5\n","    },\n","    'snow': {\n","        'epochs': 200,\n","        'style_weights': 1.5\n","    },\n","    'wet-sand': {\n","        'epochs': 200,\n","        'style_weights': 3.5\n","    },\n","    'sand-with-moss': {\n","        'epochs': 100,\n","        'style_weights': 2.5\n","    },\n","    'rain': {\n","        'epochs': 100,\n","        'style_weights': 4.5\n","    },\n","    'wood': {\n","        'epochs': 100,\n","        'style_weights': 0.5\n","    },\n","    'grass': {\n","        'epochs': 100,\n","        'style_weights': 0.1\n","    },\n","    'foliage-texture': {\n","        'epochs': 100,\n","        'style_weights': 0.5\n","    },\n","    'blue-coral': {\n","        'epochs': 100,\n","        'style_weights': 1.1\n","    }\n","}\n","\n","with open(\"./last_run_info.json\") as fp:\n","    last_run = json.load(fp)[\"last_batch\"]\n","\n","selected_textures = ['moss', 'wet-sand', 'sand-with-moss', 'rain', 'foliage-texture']\n","\n","for texture in selected_textures:\n","\n","    parser = argparse.ArgumentParser()\n","    parser.add_argument('--batch_size', type = int, default = 1)\n","    parser.add_argument('--model_name', type=str, default='vgg')\n","    parser.add_argument('--lr', type=float, default=0.05)\n","    parser.add_argument('--max_iter', type=int, default=param_dict[texture]['epochs'])\n","    args = parser.parse_args(args=[])\n","\n","    #style_img = read_image(f'./data/Textures/{texture}.jpg')\n","    #print(img.size())\n","    #layer_visualizer(img, args)\n","\n","    run_style_transfer_pipeline(args, texture, param_dict[texture]['style_weights'], last_run)"]},{"cell_type":"code","source":["from experiments.classification import Classification\n","\n","parser = argparse.ArgumentParser()\n","parser.add_argument('--batch_size', type = int, default = 64)\n","parser.add_argument('--model_name', type=str, default='resnet18')\n","parser.add_argument('--lr', type=float, default=0.001)\n","parser.add_argument('--max_iter', type=int, default=2)\n","parser.add_argument('--resize_size', type=int, default=336)\n","args = parser.parse_args(args=[])\n","\n","classification = Classification()\n","\n","classification.run_binary_classification_pipeline(args)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SXi84P_vPS9c","outputId":"c498cb91-7a41-4a69-e5bb-ac714d4ecffa"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Running epoch 0\n"]},{"output_type":"stream","name":"stderr","text":["\tRunning through training set: 100%|██████████| 75/75 [14:00<00:00, 11.21s/it]\n","\tRunning through validation set:   0%|          | 0/19 [00:00<?, ?it/s]"]}]}],"metadata":{"colab":{"provenance":[],"gpuType":"T4","machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}